# PIXIE
Orbital Project by [Team Teriri]

# Propose Level of Achievement:
   
Apollo 11

#  Project scope:
   
>We aim to deliver a standalone PC application, PIXIE, capable of processing image inputs initially in normal art forms, to pixel art outputs exhibiting characteristics of the user image, to assist game developers in creating content for non-profitable purposes.

Pixie will provide 2 different fully automated modes of conversion to deal with
common usage conditions.

Mode 1 - First Degree Conversion. Under this setting, the generated pixelated
outputs will largely preserve image details. Pixelation will focus on handling the input
image’s outlines and reducing colour steps, so as to resemble the basic
characteristics of pixel art creations. Technical focuses under this pillar will be the use
of image-processing libraries, particularly to accurately locate character outlines
through the use of colour gradient functions and by merging neighbouring pixels to
increase overall pixel size through image resizing. Considering the good preservation
of details in this conversion, end outputs will be especially useful in pixel game
dialogues and menu presentations.

Mode 2 - Final Degree Conversion. In this mode, Pixie will aim to map the user input
onto our program’s general character template. To establish this, Pixie will rely on the
use of AI (with Stable Diffusion as the linkage platform between the image and an AI
model) to accurately lift out and collect information on important areas of the input
figure (eye colour, hair type etc.) Afterwards, these key areas are then simplified and
pixelated accordingly to be mapped onto our template with the help of a trained AI
model, so as to produce a specialised output template with reference to the user input. 
Technical focuses under this conversion will be the utilisation of Stable
Diffusion to produce the end product, as well as back-end linking of the platform to
our software to ensure users will be able to complete all operations by only our
program’s UI. Ideally, the simplified and easily made-to-move nature of end products
under this conversion will be very suitable in actual gameplay presentations.

#  Core features established and changes in architecture
   
##  Changes in first-degree-conversion algorithms
A crucial step to completing first-degree conversion is being able to identify the
outline of the image.
Previously, our group utilised Laplacian Operators in the generation of the image’s
grayscale gradient map. This was a rather convenient method, as the Opencv Lib
had provided direct methods for the Operator, allowing users to be able to
straightforwardly obtain a usable gradient approximation just by calling its inbuilt
methods.

However, after numerous test trials, we realised that image outputs generated by this
method are not exactly ideal. Outputs often suffer from the issue of having their
edges identified way lesser than actual. This causes edge darkening algorithms that
come after to inaccurately process the outlining areas, showing unacceptable
instances where: 1) Supposedly consecutive darkening areas breaking apart. 2)
Certain lines were completely omitted in processing.
After intensive research, we found that Laplacian Operators are actually obtaining
estimates of the second derivatives of changes in pixel colours of an image in
cartesian coordinates. It has high tolerances towards changes in colour gradient,
specialising in only capturing abrupt changes in the image’s colour.
Though this could be ideal in cases where high sensitivity of the algorithm is required
(E.g. Identifying words from a document picture), for our purpose, especially when
there is generally high contrast between the background colours and the outlines,
such methods may instead have a negative effect and bring out a less accurate
depiction of the image outlines.
Being fully aware of this difference, we decided to switch to the counterparts of
Laplacian Operators: Sobel Operators as it has a much desirable accuracy in
identifying the outline of the image for our purpose. As this method instead initiates a
2-D spatial gradient measurement in the detection of edges, the overall change in
gradient will have to further perform Pythagoras theorem on calculated gradients in
the x and y axis directions.

